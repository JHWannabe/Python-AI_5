{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1_딥러닝의 이해.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMKzgZXybMPasK24PT1jXPq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JHWannabe/Python-AI_5/blob/main/0214%20Day1/1_%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9D%98_%EC%9D%B4%ED%95%B4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. 딥러닝의 진화**"
      ],
      "metadata": {
        "id": "Nb5O8EX_x2rh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2012**\n",
        "* CNN 중 Alex net이라는 네트워크 구조 (이미지 구별)\n",
        "* Alex net이 1등을 차지 -> CNN이 유명해지게 됨"
      ],
      "metadata": {
        "id": "hk3wqNd6yhaY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2013**\n",
        "* 아타리 게임 -> 학습을 많이 진행 -> 구석을 파서 공을 위로 올림\n",
        "* 딥마인드 -> 구글에 인수 -> 알파고"
      ],
      "metadata": {
        "id": "JrXSX0LM0PCA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2014**\n",
        "* RNN이라는 네트워크를 사용하여 중국어 -> 영어로 번역 (문자 인식)\n",
        "* 성능의 한계가 생김\n",
        "* attention 모델의 출현으로 성능이 급격히 좋아짐"
      ],
      "metadata": {
        "id": "VtCaVNgQ1G9H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2015**\n",
        "* GANs -> 오바마 합성사진\n",
        "* Residual Networks(ResNet) : CNN의 종류 중 하나\n",
        "* 사람이 이미지를 찾는 테스트 -> 5% 오차율\n",
        "* ResNet -> 3% 오차율"
      ],
      "metadata": {
        "id": "mEhgrZyV1sb9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2016**\n",
        "* 알파고 : 이세돌 9단이 컴퓨터를 이긴 마지막 인류"
      ],
      "metadata": {
        "id": "F17jZYKL39hB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2017**\n",
        "* Transformer - 번역모델\n",
        "* RNN의 단점을 극복\n",
        "* attention만으로 만든 모델\n",
        "* 자연어를 정복\n",
        "* 딥러닝에서 가장 중요한 모델 중 하나"
      ],
      "metadata": {
        "id": "brMR3U6O4lPV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2018**\n",
        "* BERT\n",
        "* Transformer에서 인코더만 따온 모델\n",
        "* 자연어를 정답없이 사용(인터넷 문장들의 데이터를 삽입)\n",
        "* 일부 글자를 가리고 가린 부분을 맞출 수 있도록 학습\n",
        "* 모델을 크게 만들고 엄청난 데이터를 사용\n",
        "* 적은 데이터(정답)를 가지고 다시 학습"
      ],
      "metadata": {
        "id": "-Yvh6J8c8LAr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2019/2020**\n",
        "* CPU 수천대를 사용하여 큰 모델을 만듦\n",
        "* 정답이 필요없이 실제 데이터만으로 셀프 수퍼바이즈 러닝"
      ],
      "metadata": {
        "id": "mkHDNqdS89KL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2.Perceptron**"
      ],
      "metadata": {
        "id": "dcv6exy99y0o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2-1. Neuron**\n",
        "![이미지](https://upload.wikimedia.org/wikipedia/commons/thumb/b/bc/Neuron_Hand-tuned.svg/400px-Neuron_Hand-tuned.svg.png)\n",
        "* 수상돌기 : 다른 뉴런들로부터 신호를 받아 특정 조건을 만족하면 축삭돌기로 보냄\n",
        "* 축삭돌기 : 전달받은 신호를 다른 뉴런으로 전달"
      ],
      "metadata": {
        "id": "IXQvjejo99vn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![이미지](https://www.thedailypost.kr/news/photo/201904/70084_60318_3157.png)\n",
        "### **파블로프의 개 실험**\n",
        "* 먹이를 봤을 때 반응하는 뉴런 -> 시냅스(강함) -> 침샘분비 뉴런\n",
        "* 종을 쳤을 때 반응하는 뉴런 -> 시냅스(약함) -> 침샘분비 뉴런\n",
        "\n",
        "> 이것을 모방해서 만든 인공신경망이 Perceptron"
      ],
      "metadata": {
        "id": "XQr_GdpKAXOE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. 딥러닝의 키포인트**"
      ],
      "metadata": {
        "id": "nJlGXXvcB-40"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 데이터\n",
        "* 모델(CNN, RNN, Transformer, Multilayer Perceptron..)\n",
        "* 알고리즘(Gradient Descent를 기초로 많은 알고리즘이 만들어짐)\n",
        "* loss function"
      ],
      "metadata": {
        "id": "CW7a-4JyCN-z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3-1. Neural Network에서의 핵심**\n",
        "* Deep Neural Network : layer 수가 최소 2개 이상인 network\n",
        "* Loss Function / Cost Function : Neural Network이 얼마나 성능이 좋은지 또는 나쁜지에 대한 척도\n",
        "* loss 값을 줄이는 방법 : 미분(접선의 기울기) 이용\n",
        "\n",
        "> 적절한 weight를 찾는 것이 핵심"
      ],
      "metadata": {
        "id": "dxLfzOJPDX78"
      }
    }
  ]
}